agent: 
  type: naive            # Type of agent to use (e.g., 'naive', 'cot', etc.)
  remember_cot: True     # Whether the agent should remember its reasoning across turns
  max_history: 16        # Maximum number of previous turns to keep in the dialogue history
  max_image_history: 0   # Maximum number of images to keep in the history
  max_cot_history: 1     # Maximum number of chain-of-thought steps to keep in history (if using 'cot' type of agent)
  max_icl_history: 1000   # Maximum number of ICL steps to keep in history (if using 'few_shot' type of agent)
  cache_icl: False

eval:
  output_dir: "results"  # Directory where evaluation results will be saved
  resume_from: null      # Path to to the incomplete results file to resume an incomplete run
  num_workers: 16        # Number of parallel workers. Increase for faster evaluation if you have enough resources
  num_episodes:          # Minimum number of episodes to run for each environment. You can optionally increase this to get more reliable results
    nle: 5               # Number of episodes for the 'nle' environment
    minihack: 5          # Number of episodes for each 'minihack' task
    code_minihack: 10          # Number of episodes for each 'minihack' task
    code_nethack: 10          # Number of episodes for each 'minihack' task
    babyai: 10           # Number of episodes for each 'babyai' task
    crafter: 10          # Number of episodes for the 'crafter' environment
    babaisai: 3          # Number of episodes for each 'babaisai' task
    textworld: 10        # Number of episodes for each 'textworld' task
  max_steps_per_episode: null   # Max steps per episode; null uses the environment default
  save_trajectories: True       # Whether to save agent trajectories (text only)
  save_images: False            # Whether to save images from the environment
  icl_episodes: 1
  icl_dataset: records

client:
  client_name: gemini           # LLM client to use (e.g., 'openai', 'gemini', 'claude')
  model_id: gemini-1.5-pro           # Model identifier (e.g., 'gpt-4', 'gpt-3.5-turbo')
  base_url: http://localhost:8080/v1   # Base URL for the API (if using a local server)
  generate_kwargs:
    temperature: 0.0            # Sampling temperature; 0.0 makes the output deterministic
    max_tokens: 1024            # Max tokens to generate in the response
  timeout: 60                   # Timeout for API requests in seconds
  max_retries: 5                # Max number of retries for failed API calls
  delay: 2                      # Exponential backoff factor between retries in seconds
  alternate_roles: False        # Whether the client requires alternating between the agent and the environment

envs:
  names: code_nethack   # Environments to evaluate, separated by hyphens
  render_mode: null
  env_kwargs:
    seed: null                # Random seed; null means a random seed is used
  nle_kwargs:
    character: "@"            # Character representing the agent in NLE
    max_episode_steps: 100_000  # Max steps per episode in NLE
    no_progress_timeout: 150    # Timeout for no progress in NLE
    savedir: null               # Directory to save NLE data; null disables saving
    save_ttyrec_every: 0        # Frequency of saving TTY recordings
    skip_more: False            # Whether to skip the 'more' prompt in NLE
  minihack_kwargs: 
    character: "@"
    max_episode_steps: 100
    penalty_step: -0.01         
    penalty_time: 0.0           
    penalty_mode: constant      
    savedir: null
    save_ttyrec_every: 0
    autopickup: False           
    skip_more: False
  code_minihack_kwargs: 
    character: null
    max_episode_steps: null
    penalty_step: 0.0
    penalty_time: 0.0
    penalty_mode: constant
    savedir: null
    save_ttyrec_every: 0
    autopickup: null
    skip_more: True
    allow_all_yn_questions: null
    allow_all_modes: null
    max_strategy_steps: 100
    add_letter_strategies: True
    add_direction_strategies: False
    add_more_strategy: False
    strategies_loc: "nle_code_wrapper.bot.strategies"
    panics_loc: "nle_code_wrapper.bot.panics"
    strategies: 
      - "goto_corridor"
      - "goto_room"
      - "descend_stairs"
      - "ascend_stairs"
      - "explore_corridor"
      - "explore_room"
      - "open_doors"
      - "open_doors_key"
      - "open_doors_kick"
      - "search_corridor_for_hidden_doors"
      - "search_room_for_hidden_doors"
    panics: 
      - "enemy_appeared"
      - "lost_hp"
  code_nethack_kwargs: 
    character: null
    max_episode_steps: null
    penalty_step: 0.0
    penalty_time: 0.0
    penalty_mode: constant
    savedir: null
    save_ttyrec_every: 0
    autopickup: null
    skip_more: True
    allow_all_yn_questions: null
    allow_all_modes: null
    max_strategy_steps: 100
    add_letter_strategies: True
    add_direction_strategies: False
    add_more_strategy: False
    strategies_loc: "nle_code_wrapper.bot.strategies"
    panics_loc: "nle_code_wrapper.bot.panics"
    strategies: 
      - "goto_corridor"
      - "goto_room"
      - "descend_stairs"
      - "ascend_stairs"
      - "explore_corridor"
      - "explore_room"
      - "open_doors"
      - "open_doors_key"
      - "open_doors_kick"
      - "search_corridor_for_hidden_doors"
      - "search_room_for_hidden_doors"
    panics: 
      - "enemy_appeared"
      - "lost_hp"
  babyai_kwargs:
    num_dists: 0                
  crafter_kwargs:
    area: [64, 64]              
    view: [9, 9]                
    size: [256, 256]            # Image size in Crafter
    reward: True                
    length: 10000               
    seed: null                  
    max_episode_steps: 2000     
  textworld_kwargs:
    objective: True             
    description: True           
    score: True                 
    max_score: True             
    won: True                   
    max_episode_steps: 80       
    textworld_games_path: tw_games  
  babaisai_kwargs: 
    add_ruleset: True

tasks:
  nle_tasks:
    - NetHackChallenge-v0       # Tasks for the NLE environment

  minihack_tasks:
    - "MiniHack-Boxoban-Hard-v0"
    - "MiniHack-Boxoban-Medium-v0"
    - "MiniHack-MazeWalk-9x9-v0"
    - "MiniHack-MazeWalk-15x15-v0"
    - "MiniHack-Corridor-R3-v0"
    - "MiniHack-CorridorBattle-Dark-v0"
    - "MiniHack-Quest-Easy-v0"
    - "MiniHack-Quest-Medium-v0"

  code_minihack_tasks:
    - "MiniHack-Corridor-R3-v0"
    - "MiniHack-Corridor-R5-v0"
    - "CustomMiniHack-Corridor-R8-v0"
    - "CustomMiniHack-Corridor-R10-v0"
    # - "MiniHack-CorridorBattle-v0"
    # - "MiniHack-CorridorBattle-Dark-v0"
    # - "MiniHack-WoD-Hard-Full-v0"
    # - "MiniHack-WoD-Pro-Full-v0"
    # - "MiniHack-River-v0"
    # - "MiniHack-River-Monster-v0"
    # - "MiniHack-River-Lava-v0"
    # - "MiniHack-River-MonsterLava-v0"
    # - "MiniHack-River-Narrow-v0"
    # - "MiniHack-Quest-Easy-v0"
    # - "MiniHack-Quest-Medium-v0"
    # - "MiniHack-Quest-Hard-v0"
    # - "MiniHack-MultiRoom-N10-v0"
    # - "MiniHack-MultiRoom-N6-Locked-v0"
    # - "MiniHack-MultiRoom-N10-Lava-v0"
    # - "MiniHack-MultiRoom-N6-Monster-v0"
    # - "MiniHack-MultiRoom-N6-Extreme-v0"
    # - "MiniHack-MultiRoom-N6-LavaMonsters-v0"
    # - "MiniHack-Freeze-Lava-Full-v0"
    # - "MiniHack-LavaCross-Levitate-Full-v0"
    # - "MiniHack-LavaCross-Full-v0"
    # - "MiniHack-HideNSeek-Mapped-v0"
    # - "MiniHack-HideNSeek-v0"
    # - "MiniHack-HideNSeek-Lava-v0"
    # - "MiniHack-HideNSeek-Big-v0"

  code_nethack_tasks:
    - "NetHackScore-v0"

  crafter_tasks:
    - "default"                 # Tasks for Crafter

  babyai_tasks:
    - "BabyAI-MixedTrainLocal-v0/goto"
    - "BabyAI-MixedTrainLocal-v0/pickup"
    - "BabyAI-MixedTrainLocal-v0/open"
    - "BabyAI-MixedTrainLocal-v0/putnext"
    - "BabyAI-MixedTrainLocal-v0/pick_up_seq_go_to"

  textworld_tasks:
    - "treasure_hunter"
    - "the_cooking_game"
    - "coin_collector"

  babaisai_tasks:
    - "env/make_win-distr_obj_rule"
    - "env/goto_win-distr_obj_rule"
    - "env/goto_win"
    - "env/goto_win-distr_obj"
    - "env/goto_win-distr_rule"
    - "env/goto_win-distr_obj-irrelevant_rule"
    - "env/make_win-distr_obj"
    - "env/make_win-distr_rule"
    - "env/make_win"
    - "env/make_win-distr_obj-irrelevant_rule"
    - "env/two_room-goto_win"
    - "env/two_room-goto_win-distr_obj_rule"
    - "env/two_room-goto_win-distr_rule"
    - "env/two_room-goto_win-distr_obj"
    - "env/two_room-goto_win-distr_obj-irrelevant_rule"
    - "env/two_room-goto_win-distr_win_rule"
    - "env/two_room-break_stop-goto_win-distr_obj_rule"
    - "env/two_room-break_stop-goto_win-distr_obj"
    - "env/two_room-break_stop-goto_win-distr_rule"
    - "env/two_room-break_stop-goto_win-distr_obj-irrelevant_rule"
    - "env/two_room-break_stop-goto_win"
    - "env/two_room-maybe_break_stop-goto_win-distr_obj_rule"
    - "env/two_room-maybe_break_stop-goto_win"
    - "env/two_room-maybe_break_stop-goto_win-distr_obj"
    - "env/two_room-maybe_break_stop-goto_win-distr_rule"
    - "env/two_room-maybe_break_stop-goto_win-distr_obj-irrelevant_rule"
    - "env/two_room-make_win-distr_obj_rule"
    - "env/two_room-make_win-distr_rule"
    - "env/two_room-make_win"
    - "env/two_room-make_win-distr_obj-irrelevant_rule"
    - "env/two_room-make_win-distr_obj"
    - "env/two_room-make_win-distr_win_rule"
    - "env/two_room-break_stop-make_win-distr_obj_rule"
    - "env/two_room-break_stop-make_win-distr_rule"
    - "env/two_room-break_stop-make_win"
    - "env/two_room-break_stop-make_win-distr_obj-irrelevant_rule"
    - "env/two_room-break_stop-make_win-distr_obj"
    - "env/two_room-make_you"
    - "env/two_room-make_you-make_win"
    - "env/two_room-make_wall_win"

hydra:
  run:
    dir: .                     # Set the working directory to the current directory
  output_subdir: null          # Do not use an output subdirectory